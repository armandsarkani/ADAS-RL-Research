{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Min-Max, a perfect Tic Tac Toe player \n",
    "In this Notebook, we will use the Min-Max algorithm to create a computer player which will be able to play Tic Tac Toe perfectly. That is, the player will always play the best possible move in a given situation. This player will give us a good benchmark to compare the other players against.\n",
    "\n",
    "Let's start by importing a few of the utility functions and classes we defined last time and make sure it all still works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    .rendered_html table, .rendered_html th, .rendered_html tr, .rendered_html td {\n",
       "      border: 1px  black solid !important;\n",
       "      color: black !important;\n",
       "    }\n",
       "    </style>\n",
       "    <table border=\"1\"><tr><td>o</td><td>x</td><td>x</td></tr><tr><td>o</td><td>x</td><td>&ensp;</td></tr><tr><td>&ensp;</td><td>x</td><td>o</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross won\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "from tic_tac_toe.Board import Board, GameResult, CROSS, NAUGHT, EMPTY\n",
    "from util import print_board, play_game\n",
    "from tic_tac_toe.RandomPlayer import RandomPlayer\n",
    "\n",
    "board = Board()\n",
    "player1 = RandomPlayer()\n",
    "player2 = RandomPlayer()\n",
    "\n",
    "result = play_game(board, player1, player2)\n",
    "print_board(board)\n",
    "\n",
    "if result == GameResult.CROSS_WIN:\n",
    "    print(\"Cross won\")\n",
    "elif result == GameResult.NAUGHT_WIN:\n",
    "    print(\"Naught won\")\n",
    "else:\n",
    "    print(\"Draw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Min-Max algorithm\n",
    "So, what is this Min-Max algorithm that we want to implement?\n",
    "\n",
    "The long answer can be found [here](https://en.wikipedia.org/wiki/Minimax). We won't go into that much detail here and just look at the general idea:\n",
    "\n",
    "Given a board state, we find the best move by simulating all possible continuations from this position and chose the one that is best for us. The one best for us is the one with the best outcome if we assume:\n",
    "\n",
    "* we always make the move that is best for us (*Maximizes* the game value for us) and \n",
    "* our opponent always makes the move that is best for them (and thus worst for us - *Minimizing* the game value for us). \n",
    "\n",
    "You can see where the algorithm gets its name from. This algorithm, and variations of it, is very popular for writing game engines that play games like Tik Tak Toe, Chess, Checkers, etc. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Side Note: For games with a large number of different board positions like Chess, the algorithm will generally not be able to completely simulate all continuations. In those cases the algorithm will only look ahead a certain number of moves and estimate the value of the position then. Also, more advanced versions of this algorithm, e.g. [alpha / beta pruning](https://en.wikipedia.org/wiki/Alpha%E2%80%93beta_pruning) are used in those cases.\n",
    "</div>\n",
    "\n",
    "Let's look at an exmaple. Given the followin board state and NAUGHT to move next:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    .rendered_html table, .rendered_html th, .rendered_html tr, .rendered_html td {\n",
       "      border: 1px  black solid !important;\n",
       "      color: black !important;\n",
       "    }\n",
       "    </style>\n",
       "    <table border=\"1\"><tr><td>x</td><td>&ensp;</td><td>x</td></tr><tr><td>o</td><td>o</td><td>x</td></tr><tr><td>&ensp;</td><td>&ensp;</td><td>o</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example = Board([CROSS  , EMPTY  , CROSS,\n",
    "                 NAUGHT , NAUGHT , CROSS,\n",
    "                 EMPTY  , EMPTY  , NAUGHT])\n",
    "print_board(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following continuations are possible:\n",
    "![title](./Images/TicTacToe-MinMax-Example1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is: first NAUGHT, the maximizing player, gets to move, then CROSS, the minimizing player, gets to move and in those cases where the game has not ended at that point, NAUGHT, the maximizing player, gets one more move:\n",
    "![title](./Images/TicTacToe-MinMax-Example2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We label all final game states according to their value from the point of view of Naught: \n",
    "* 1 for a win\n",
    "* -1 for a loss\n",
    "* 0 for a draw\n",
    "\n",
    "![title](./Images/TicTacToe-MinMax-Example3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can back-propagate the scores from the bottom layer to the layer above. According to the algorithm, as it is the maximizing player's turn, we chose the move with the highest score. \n",
    "\n",
    "Note that in this initial case, as there is only one possible move and the move thus is forced, we just propagate that value one layer up without having to chose a maximizing move:\n",
    "\n",
    "![title](./Images/TicTacToe-MinMax-Example4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we propagate up again. This time it is the minimizing player's turn, so we propagate the smaller values for each possible move up:\n",
    "\n",
    "![title](./Images/TicTacToe-MinMax-Example5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we propagate one more layer up. This time it's the maximizing player again, so we chose the highest possible value of all moves for the position:\n",
    "\n",
    "![title](./Images/TicTacToe-MinMax-Example6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we know everything we need to know to make a move: \n",
    "\n",
    "* The best we can hope for, if both we and our opponent always plays their best move, is a draw (since the value of the current board position is 0). \n",
    "\n",
    "* We also know that there is only 1 move in the current situation that will achieve this best case for us: Putting a NAUGHT in the middle spot on the top row.\n",
    "\n",
    "Note that there are other potential continuation that would also lead to a draw, and some that might even lead to NAUGHT winning. Unfortunately, however, we also know now that if CROSS always plays their best move, we won't ever have a chance to to reach any of these outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## The Min-Max Player Code\n",
    "Our code contains 2 player classes which implement the Min Max algorithm for playing Tic Tac Toe:\n",
    "\n",
    "* [MinMaxAgent.py](https://github.com/fcarsten/tic-tac-toe/blob/master/tic_tac_toe/MinMaxAgent.py): Plays Tic Tac Toe using the Min Max Algorithm in a deterministic way. I.e. if there is more than 1 move with euqal best scores in a given position, this player will always chose the same move.\n",
    "\n",
    "* [RndMinMaxAgent.py](https://github.com/fcarsten/tic-tac-toe/blob/master/tic_tac_toe/RndMinMaxAgent.py): Plays Tic Tac Toe using the Min Max Algorithm in a non-deterministic way. I.e. if there is more than 1 move with euqal best scores in a given position this player will each time randomly chose between them.\n",
    "\n",
    "In order to make things a bit more efficient, the players will also store the value for a given board position in an internal cache. This means, that they only have to compute the possible continuations from each position once. It even makes this first computation more efficient, as often different move combination will produce the same board position, which, with the cached result, we don't have to evaluate again.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Side Note: Even on a moderately fast computer this works quite well due to the small number of possible board positions in Tic Tac Toe: <br/><br/>\n",
    "\n",
    "While a game can have something like $9! = 362,800$ different possible move combinations, i.e. 9 choices for the first move, 8 choices for the second move, 7 choices for the 3rd move etc down to 1 choice for the last move (and for simpicity ignoring the fact that the game can be over before all squares are occupied - thus reducing the actual number of move combinations), the game can only have $3^9 = 19,683$ different states as each square can only either be empty, have a NAUGHT, or have a CROSS in it (again for simplicity ignoring the fact that these include game states that are impossible in a real game; also ignoring the fact that we could reduce the number of states further by treating symmetric position as being the same). \n",
    "</div>\n",
    "\n",
    "Let's see how they perform.\n",
    "\n",
    "First we define a small utility function which we call `battle` to repeatedly pit 2 players against each other for a number of games. After the \"battle\" has finished, the function will return statistics about who won how often."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tic_tac_toe.Player import Player\n",
    "\n",
    "def battle(player1: Player, player2: Player, num_games: int = 100000):\n",
    "    board = Board()\n",
    "    draw_count = 0\n",
    "    cross_count = 0\n",
    "    naught_count = 0\n",
    "    for _ in range(num_games):\n",
    "        result = play_game(board, player1, player2)\n",
    "        if result == GameResult.CROSS_WIN:\n",
    "            cross_count += 1\n",
    "        elif result == GameResult.NAUGHT_WIN:\n",
    "            naught_count += 1\n",
    "        else:\n",
    "            draw_count += 1\n",
    "\n",
    "    print(\"After {} game we have draws: {}, Player 1 wins: {}, and Player 2 wins: {}.\".format(num_games, draw_count,\n",
    "                                                                                         cross_count, naught_count))\n",
    "\n",
    "    print(\"Which gives percentages of draws: {:.2%}, Player 1 wins: {:.2%}, and Player 2 wins:  {:.2%}\".format(\n",
    "        draw_count / num_games, cross_count / num_games, naught_count / num_games))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use this function and to start of with we pit the MinMaxAgent against the RandomPlayer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 100000 game we have draws: 489, Player 1 wins: 99511, and Player 2 wins: 0.\n",
      "Which gives percentages of draws: 0.49%, Player 1 wins: 99.51%, and Player 2 wins:  0.00%\n"
     ]
    }
   ],
   "source": [
    "from tic_tac_toe.MinMaxAgent import MinMaxAgent\n",
    "\n",
    "battle(MinMaxAgent(), RandomPlayer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "And now, with the Random player going first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 100000 game we have draws: 19323, Player 1 wins: 0, and Player 2 wins: 80677.\n",
      "Which gives percentages of draws: 19.32%, Player 1 wins: 0.00%, and Player 2 wins:  80.68%\n"
     ]
    }
   ],
   "source": [
    "battle(RandomPlayer(), MinMaxAgent())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And just for validation, the 2 MinMax players against each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 100000 game we have draws: 100000, Player 1 wins: 0, and Player 2 wins: 0.\n",
      "Which gives percentages of draws: 100.00%, Player 1 wins: 0.00%, and Player 2 wins:  0.00%\n"
     ]
    }
   ],
   "source": [
    "from tic_tac_toe.RndMinMaxAgent import RndMinMaxAgent\n",
    "\n",
    "battle(MinMaxAgent(), RndMinMaxAgent())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected and to my relief, we get 100% draws.\n",
    "\n",
    "# Baseline Part 2\n",
    "\n",
    "This gives us an additional baseline:\n",
    "\n",
    "| Player | P1 Win | P2 Win | Draw |\n",
    "| --- | ---| --- | --- |\n",
    "| Min Max - Random | 99.5%     | 0%     | 0.5% |\n",
    "| Random - Min Max | 0%    | 80% | 20% |\n",
    "| Min Max - Min Max | 0%    | 0% | 100% |\n",
    "\n",
    "This means, in order to be considered as playing better than pure random, a player should achieve significantly more than 20% draws against a Min-Max player when going first and significantly more than 1% draws when going second.\n",
    "\n",
    "In the next part we will look at our first player using reinforcement learning: The Tabular Q-Learner."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
